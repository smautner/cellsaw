{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbeefd9-ac74-4b6e-80ad-3d809e9cb1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc39be0-4b98-4a78-beed-259c51c4ca72",
   "metadata": {},
   "source": [
    "- we compare the distance measure for the same time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f770d2-650d-4226-b5bd-a58e6f8388f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "mpl.rc(\"figure\", dpi=100)\n",
    "import numpy as np\n",
    "import jack\n",
    "from lmz import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efb479-1280-4ab9-818b-92e8fcac99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "import cellsaw\n",
    "import cellsaw.io_utils\n",
    "import notebookhelper\n",
    "\n",
    "loaders = [jack.loads5 , jack.load509, jack.load1290]\n",
    "loaders += [jack.getmousecortex, jack.loadwater, jack.pancreatic, jack.loadcereb]\n",
    "\n",
    "labels = ['Assigned_subcluster','Cluster','New_cellType','labels','label','labels','celltype','labels']\n",
    "\n",
    "# loading data-> [[[anndata]]] \n",
    "#datasets = [ [load(subsample=1000, seed = seed) for load in loaders] for seed in [31337,42,69,420,1312]]\n",
    "datasets = [ load(subsample=1000, seed = 45)[-4:] for load in loaders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fc431-8ce3-4b67-9e2e-9426ce0cea29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a3509-cffe-4d46-bb6b-417e86c9bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "import scanorama\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn import metrics\n",
    "if False:\n",
    "    for i,(dataset,label) in enumerate(zip(datasets,labels)):\n",
    "        scanorama.integrate_scanpy(dataset)\n",
    "        y = dataset[-1].obs[label]\n",
    "        src = dataset[-1].obsm['X_scanorama']\n",
    "        diffusor = LabelPropagation(gamma = .75).fit(src,y)\n",
    "\n",
    "        target = dataset[:-1]\n",
    "        predicted = diffusor.predict( np.vstack([a.obsm['X_scanorama'] for a in target]) )\n",
    "        size  = [ x.X.shape[0] for x in target]\n",
    "        pred = np.split(predicted,np.add.accumulate(size))\n",
    "        results+=[{'method':'scanorama','dataset':i, 'slice':j, 'score':metrics.adjusted_rand_score(t.obs[label],p) } \n",
    "                      for j,(t,p) in enumerate(zip(target,pred))]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c97fb-b5c1-4632-8c5d-68edc7ac89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add.accumulate([4,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145ddb5-107e-477e-a88f-7f3c693f7f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a66f4c-c8b0-4143-a229-e4e0b5b8562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn import metrics\n",
    "from cellsaw.merge import diffusion\n",
    "import functools\n",
    "from cellsaw.merge import Merge\n",
    "from cellsaw import preprocess as prep\n",
    "if False:\n",
    "    for i,(dataset,label) in enumerate(zip(datasets,labels)):\n",
    "        target = dataset[:-1]\n",
    "        # PCA\n",
    "        prep.annotate_genescore(dataset,selector = 'cell_ranger')\n",
    "        m = Merge(dataset,pca=50) \n",
    "\n",
    "        # prepare kernel\n",
    "        targetsizes  = [ x.X.shape[0] for x in target]\n",
    "        krnl = functools.partial( diffusion.linear_assignment_kernel_XXX, tsizes = targetsizes)\n",
    "\n",
    "        # fit predict\n",
    "        diffusor = diffusion.Diffusion(n_neighbors_intra=5, \n",
    "                                     n_neighbors_inter= 4,\n",
    "                                     sigmafac = 64,\n",
    "                                     linear_assignment_factor=5,\n",
    "                                     kernel = krnl)\n",
    "        y = dataset[-1].obs[label]\n",
    "        diffusor.fit(m.projections[1][-1],y)\n",
    "        predicted = diffusor.predict( np.vstack(m.projections[1][:-1]) )\n",
    "\n",
    "        # split precition\n",
    "        pred = np.split(predicted,np.add.accumulate(targetsizes))\n",
    "        results+=[{'method':'Ours','dataset':i, 'slice':j, 'score':metrics.adjusted_rand_score(t.obs[label],p) } \n",
    "                      for j,(t,p) in enumerate(zip(target,pred))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26351b3-7ba5-4b3e-ad21-49974836ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn import metrics\n",
    "from cellsaw.merge import diffusion\n",
    "import functools\n",
    "from cellsaw.merge import Merge\n",
    "from cellsaw import preprocess as prep\n",
    "from ubergauss import tools\n",
    "from lmz import *\n",
    "    \n",
    "def mkscr(i):\n",
    "    dataset = datasets[i]\n",
    "    label = labels[i]\n",
    "    \n",
    "    target = dataset[:-1]\n",
    "    target.reverse()\n",
    "    # PCA\n",
    "    prep.annotate_genescore(dataset,selector = 'cell_ranger')\n",
    "    m = Merge(dataset,pca=50) \n",
    "    \n",
    "    # prepare kernel\n",
    "    targetsizes  = [ x.X.shape[0] for x in target]\n",
    "    krnl = functools.partial( diffusion.linear_assignment_kernel_XXX, tsizes = targetsizes)\n",
    "    \n",
    "    # fit predict\n",
    "    diffusor = diffusion.Diffusion(n_neighbors_intra=5, \n",
    "                                 n_neighbors_inter= 4,\n",
    "                                 sigmafac = 64,\n",
    "                                 linear_assignment_factor=5,\n",
    "                                 kernel = krnl)\n",
    "    y = dataset[-1].obs[label]\n",
    "    diffusor.fit(m.projections[1][-1],y)\n",
    "    predicted = diffusor.predict( np.vstack(m.projections[1][:-1]) )\n",
    "    \n",
    "    # split precition\n",
    "    pred = np.split(predicted,np.add.accumulate(targetsizes))\n",
    "    return [{'method':'Ours','dataset':i, 'slice':j, 'score':metrics.adjusted_rand_score(t.obs[label],p) } \n",
    "                  for j,(t,p) in enumerate(zip(target,pred))]\n",
    "\n",
    "\n",
    "#zz = tools.xmap(mkscr,Range(datasets))\n",
    "#zzz = [z for zzz in zz for z in zzz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de685174-2e73-4b46-9d88-bc8582c15c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28568f-83e2-4d88-82a4-6c9b0be319a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(zzz+results)\n",
    "sns.boxplot(data = df, x='score', y= 'method')\n",
    "sns.heatmap(df.pivot_table('score','method','dataset'),square=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85222fb0-3417-4c80-a336-8257532e27a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e53fc-ea36-409c-9d54-dc7092f6c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in datasets:\n",
    "    print(len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b92da6-9115-4bc7-978e-6d1f8799a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn import metrics\n",
    "from cellsaw.merge import diffusion\n",
    "import functools\n",
    "from cellsaw.merge import Merge\n",
    "from cellsaw import preprocess as prep\n",
    "from ubergauss import tools\n",
    "from lmz import *\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "\n",
    "\n",
    "def mkscr(xxx):\n",
    "    i, par = xxx\n",
    "    pid, na , nr ,sig, lsa,umap = par['pid'],par['na'],par['nr'],par['sig'],par['lsa'],par['umap']\n",
    "    dataset = [d.copy() for d in datasets[i]]\n",
    "    dataset.reverse()\n",
    "    label = labels[i]\n",
    "    target = dataset[1:]\n",
    "    \n",
    "    # PCA\n",
    "    prep.annotate_genescore(dataset,selector = 'cell_ranger')\n",
    "    m = Merge(dataset,pca=50,umaps = [umap]) \n",
    "    \n",
    "    # prepare kernel\n",
    "    targetsizes  = [ x.X.shape[0] for x in target]\n",
    "    krnl = functools.partial( diffusion.linear_assignment_kernel_XXX, tsizes = targetsizes)\n",
    "    \n",
    "    # fit predict\n",
    "    diffusor = diffusion.Diffusion(n_neighbors_intra=na, \n",
    "                                 n_neighbors_inter= nr,\n",
    "                                 sigmafac = sig,\n",
    "                                 linear_assignment_factor=lsa,\n",
    "                                 kernel = krnl)\n",
    "    y = dataset[0].obs[label]\n",
    "    diffusor.fit(m.projections[pid][0],y)\n",
    "    predicted = diffusor.predict( np.vstack(m.projections[pid][1:]) )\n",
    "    # split precition\n",
    "    pred = np.split(predicted,np.add.accumulate(targetsizes))\n",
    "    res =  [{'method':'Ours','dataset':i, 'slice':j, 'score':metrics.adjusted_rand_score(t.obs[label],p) }  for j,(t,p) in enumerate(zip(target,pred))]\n",
    "    return np.mean([r['score'] for r in res]) \n",
    "\n",
    "\n",
    "\n",
    "def evalparams(params):\n",
    "    print(params)\n",
    "    return -np.mean(tools.xmap(mkscr, ( (i,params) for i in Range(datasets)) ))\n",
    "\n",
    "def optimize():\n",
    "    #pid, na , nr ,sig, lsa,umap = par['pid'],par['na'],par['nr'],par['sig'],par['lsa'],par['umap']\n",
    "    space = { \n",
    "        'umap' :          scope.int(hp.quniform('umap',5,15,1)),\n",
    "        'lsa':hp.uniform('lsa',.001,10),\n",
    "        'sig':hp.uniform('sig',.001,100),\n",
    "        'na' :          scope.int(hp.quniform('na',1,10,1)),\n",
    "        'nr' :          scope.int(hp.quniform('nr',1,10,1)),\n",
    "        'pid' :          scope.int(hp.quniform('pid',1,2,1))\n",
    "    } #hp.uniform('linear_assignment_factor',4,12)}\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=evalparams,\n",
    "                space = space,\n",
    "        algo=tpe.suggest,\n",
    "        trials = trials,\n",
    "        max_evals=100)\n",
    "\n",
    "    print(best)\n",
    "    return trials\n",
    "\n",
    "t = optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e88738-35ca-43ad-94d4-7195632660df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
